{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_CTC_Vietnamese_Recognition_40epochs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/huyhoang17/Colab_Temporary/blob/master/[Overfitting]Training_CTC_Vietnamese_Recognition_40epochs.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "4qQkFHnrwixn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfea88cb-fc24-419c-aee3-9736ebd5605d"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3SyRUanny2aR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "33194fa7-ff04-4230-de46-493acbdc1cc3"
      },
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive/Japanese_Recognition/datasets"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anpr_ocr      model\t\t\t  vn_handwriting_data.zip\n",
            "anpr_ocr.zip  pp_vn_handwriting_data\t  wordlist_bi_clean.txt\n",
            "ETL1\t      pp_vn_handwriting_data.zip  wordlist_mono_clean.txt\n",
            "IAM_dataset   transcription.pk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "haVgOTr-Es6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import os\n",
        "import pickle\n",
        "# TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "# print(TPU_WORKER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-LnOdZA5fmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !rm -rf drive/My\\ Drive/Japanese_Recognition/datasets/pp_vn_handwriting_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L6_swBz9-O1L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !unzip drive/My\\ Drive/Japanese_Recognition/datasets/pp_vn_handwriting_data.zip -d drive/My\\ Drive/Japanese_Recognition/datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BC83ooB3yija",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# zip_ref = zipfile.ZipFile('drive/My Drive/Japanese_Recognition/datasets/pp_vn_handwriting_data.zip', 'r')\n",
        "# zip_ref.extractall('drive/My Drive/Japanese_Recognition/datasets')\n",
        "# zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vI9Au8IW6WCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "813a9a3a-11df-4fdb-d29b-10985560802f"
      },
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive/Japanese_Recognition/datasets/pp_vn_handwriting_data | wc -l "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "56AYZWUI7WGz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e247afc-5577-45a2-820f-25174dec71c7"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('drive/My Drive/Japanese_Recognition/datasets/transcription.pk', 'rb') as f:  # noqa\n",
        "    data = pickle.load(f)\n",
        "no_samples = len(data)\n",
        "print(no_samples)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c4IaycD10EFk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pp_dataset = 'drive/My Drive/Japanese_Recognition/datasets/pp_vn_handwriting_data'\n",
        "img_size = (1150, 32)\n",
        "no_epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2JrkIt5oxnVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6a5b8ad0-3082-4a35-853a-114ded6077d9"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "print('Keras version:', keras.__version__)\n",
        "import os\n",
        "from os.path import join\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import pylab\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Dense, Activation\n",
        "from keras.layers import Reshape, Lambda\n",
        "from keras.layers.merge import add, concatenate\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing import image\n",
        "import keras.callbacks\n",
        "import cv2"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 1.11.0\n",
            "Keras version: 2.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DxAH3MKjxVMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = '\\ !%\"#&\\'()*+,-./0123456789:;?AÁẢÀÃẠÂẤẨẦẪẬĂẮẲẰẴẶBCDĐEÉẺÈẼẸÊẾỂỀỄỆFGHIÍỈÌĨỊJKLMNOÓỎÒÕỌÔỐỔỒỖỘƠỚỞỜỠỢPQRSTUÚỦÙŨỤƯỨỬỪỮỰVWXYÝỶỲỸỴZaáảàãạâấẩầẫậăắẳằẵặbcdđeéẻèẽẹêếểềễệfghiíỉìĩịjklmnoóỏòõọôốổồỗộơớởờỡợpqrstuúủùũụưứửừữựvwxyýỷỳỹỵz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lyjY5oqx1jEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7bbe708-8503-476a-de0a-34ccd7916285"
      },
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "QNbh90B6sgcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5032d3cc-e84d-4600-982c-19faac872877"
      },
      "cell_type": "code",
      "source": [
        "chars_ = []\n",
        "for char in chars:\n",
        "  chars_.append(char)\n",
        "print(chars_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\\\', ' ', '!', '%', '\"', '#', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'Á', 'Ả', 'À', 'Ã', 'Ạ', 'Â', 'Ấ', 'Ẩ', 'Ầ', 'Ẫ', 'Ậ', 'Ă', 'Ắ', 'Ẳ', 'Ằ', 'Ẵ', 'Ặ', 'B', 'C', 'D', 'Đ', 'E', 'É', 'Ẻ', 'È', 'Ẽ', 'Ẹ', 'Ê', 'Ế', 'Ể', 'Ề', 'Ễ', 'Ệ', 'F', 'G', 'H', 'I', 'Í', 'Ỉ', 'Ì', 'Ĩ', 'Ị', 'J', 'K', 'L', 'M', 'N', 'O', 'Ó', 'Ỏ', 'Ò', 'Õ', 'Ọ', 'Ô', 'Ố', 'Ổ', 'Ồ', 'Ỗ', 'Ộ', 'Ơ', 'Ớ', 'Ở', 'Ờ', 'Ỡ', 'Ợ', 'P', 'Q', 'R', 'S', 'T', 'U', 'Ú', 'Ủ', 'Ù', 'Ũ', 'Ụ', 'Ư', 'Ứ', 'Ử', 'Ừ', 'Ữ', 'Ự', 'V', 'W', 'X', 'Y', 'Ý', 'Ỷ', 'Ỳ', 'Ỹ', 'Ỵ', 'Z', 'a', 'á', 'ả', 'à', 'ã', 'ạ', 'â', 'ấ', 'ẩ', 'ầ', 'ẫ', 'ậ', 'ă', 'ắ', 'ẳ', 'ằ', 'ẵ', 'ặ', 'b', 'c', 'd', 'đ', 'e', 'é', 'ẻ', 'è', 'ẽ', 'ẹ', 'ê', 'ế', 'ể', 'ề', 'ễ', 'ệ', 'f', 'g', 'h', 'i', 'í', 'ỉ', 'ì', 'ĩ', 'ị', 'j', 'k', 'l', 'm', 'n', 'o', 'ó', 'ỏ', 'ò', 'õ', 'ọ', 'ô', 'ố', 'ổ', 'ồ', 'ỗ', 'ộ', 'ơ', 'ớ', 'ở', 'ờ', 'ỡ', 'ợ', 'p', 'q', 'r', 's', 't', 'u', 'ú', 'ủ', 'ù', 'ũ', 'ụ', 'ư', 'ứ', 'ử', 'ừ', 'ữ', 'ự', 'v', 'w', 'x', 'y', 'ý', 'ỷ', 'ỳ', 'ỹ', 'ỵ', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4azzwbUsso2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5db09b4-8639-464d-ffc8-9eacb4ba720e"
      },
      "cell_type": "code",
      "source": [
        "len(chars_)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "BCq_QEZM2BJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import logging\n",
        "def get_logger(name):\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    # formatter\n",
        "    fmt = logging.Formatter(\n",
        "        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "    )\n",
        "\n",
        "    # handler\n",
        "    handler = logging.StreamHandler()\n",
        "    handler.setLevel(logging.DEBUG)\n",
        "#     file_handler = logging.FileHandler(cf.LOGGING, mode='a')\n",
        "#     file_handler.setLevel(logging.DEBUG)\n",
        "    handler.setFormatter(fmt)\n",
        "#     file_handler.setFormatter(fmt)\n",
        "\n",
        "    # add handler to formatter\n",
        "    logger.addHandler(handler)\n",
        "#     logger.addHandler(file_handler)\n",
        "\n",
        "    return logger\n",
        "logger = get_logger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uusd0ma2xO6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def labels_to_text(letters, labels):\n",
        "    return ''.join(list(map(lambda x: letters[x] if x < len(letters) else \"\", labels)))  # noqa\n",
        "\n",
        "\n",
        "def text_to_labels(letters, text):\n",
        "    return list(map(lambda x: letters.index(x), text))\n",
        "\n",
        "\n",
        "def decode_batch(out):\n",
        "    ret = []\n",
        "    for j in range(out.shape[0]):\n",
        "        out_best = list(np.argmax(out[j, 2:], 1))\n",
        "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
        "        outstr = labels_to_text(out_best)\n",
        "        ret.append(outstr)\n",
        "    return ret\n",
        "\n",
        "\n",
        "def decode_predict_ctc(out, chars, top_paths=1):\n",
        "    results = []\n",
        "    beam_width = 5\n",
        "    if beam_width < top_paths:\n",
        "        beam_width = top_paths\n",
        "    for i in range(top_paths):\n",
        "        lables = K.get_value(\n",
        "            K.ctc_decode(\n",
        "                out, input_length=np.ones(out.shape[0]) * out.shape[1],\n",
        "                greedy=False, beam_width=beam_width, top_paths=top_paths\n",
        "            )[0][i]\n",
        "        )[0]\n",
        "        text = labels_to_text(chars, lables)\n",
        "        results.append(text)\n",
        "    return results\n",
        "\n",
        "\n",
        "def predit_a_image(model_p, pimg, top_paths=1):\n",
        "    # c = np.expand_dims(a.T, axis=0)\n",
        "    net_out_value = model_p.predict(pimg)\n",
        "    top_pred_texts = decode_predict_ctc(net_out_value, top_paths)\n",
        "    return top_pred_texts\n",
        "\n",
        "\n",
        "def is_valid_str(letters, s):\n",
        "    for ch in s:\n",
        "        if ch not in letters:\n",
        "            return False\n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DXE1cQ6AxZSS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN\n",
        "    # tend to be garbage:\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5NkXRkTxfTQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def CRNN_model():\n",
        "    act = 'relu'\n",
        "    input_data = Input(name='the_input', shape=img_size + (1, ), dtype='float32')\n",
        "    inner = Conv2D(16, (3, 3), padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv1')(input_data)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(\n",
        "        inner)\n",
        "    inner = Conv2D(32, (3, 3), padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv2')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(\n",
        "        inner)\n",
        "    inner = Conv2D(64, (3, 3), padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv3')(input_data)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max3')(\n",
        "        inner)\n",
        "    inner = Conv2D(128, (3, 3), padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv4')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max4')(\n",
        "        inner)\n",
        "    inner = Conv2D(256, (3, 3), padding='same',\n",
        "                   activation=act, kernel_initializer='he_normal',\n",
        "                   name='conv5')(inner)\n",
        "    inner = MaxPooling2D(pool_size=(2, 2), name='max5')(\n",
        "        inner)\n",
        "\n",
        "#     conv_to_rnn_dims = (1150 // (2 ** 2),\n",
        "#                         (32 // (2 ** 2)) * 16)\n",
        "    conv_to_rnn_dims = (256, 572)\n",
        "    print(conv_to_rnn_dims)\n",
        "#     import pdb; pdb.set_trace()\n",
        "    inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
        "  \n",
        "    # cuts down input size going into RNN:\n",
        "    # TIME_DENSE_SIZE = 256\n",
        "    inner = Dense(256, activation=act, name='dense1')(inner)\n",
        "\n",
        "    gru_1 = GRU(256, return_sequences=True,\n",
        "                kernel_initializer='he_normal', name='gru1')(inner)\n",
        "    gru_1b = GRU(256, return_sequences=True, go_backwards=True,\n",
        "                 kernel_initializer='he_normal', name='gru1_b')(inner)\n",
        "    gru1_merged = add([gru_1, gru_1b])\n",
        "    gru_2 = GRU(256, return_sequences=True,\n",
        "                kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
        "    gru_2b = GRU(256, return_sequences=True, go_backwards=True,\n",
        "                 kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
        "\n",
        "    # transforms RNN output to character activations:\n",
        "    # no unique labels\n",
        "    inner = Dense(216, kernel_initializer='he_normal',\n",
        "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
        "    y_pred = Activation('softmax', name='softmax')(inner)\n",
        "\n",
        "    Model(inputs=input_data, outputs=y_pred).summary()\n",
        "\n",
        "    labels = Input(name='the_labels', shape=[256], dtype='float32')\n",
        "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "    # loss function\n",
        "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')(\n",
        "        [y_pred, labels, input_length, label_length]\n",
        "    )\n",
        "\n",
        "    model = Model(inputs=[input_data, labels,\n",
        "                          input_length, label_length], outputs=loss_out)\n",
        "\n",
        "    y_func = K.function([input_data], [y_pred])\n",
        "\n",
        "    return model, y_func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6qwD7COlxBoT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TextSequenceGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates data for Keras\"\"\"\n",
        "\n",
        "    def __init__(self, samples, batch_size=16,\n",
        "                 img_size=img_size, max_text_len=160,\n",
        "                 downsample_factor=4, shuffle=True):\n",
        "        # train 95, test 5\n",
        "        imgs, gt_texts = [], []\n",
        "        for sample in samples:\n",
        "            img = list(sample.keys())[0]\n",
        "            fn_path = os.path.join(pp_dataset, img.split('/')[-1])\n",
        "            imgs.append(fn_path)\n",
        "            gt_texts.append(list(sample.values())[0])\n",
        "        self.imgs = imgs\n",
        "        self.gt_texts = gt_texts\n",
        "\n",
        "        self.max_text_len = max_text_len\n",
        "        self.chars = chars\n",
        "        self.blank_label = len(self.chars)\n",
        "        self.ids = range(len(self.imgs))\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.img_w, self.img_h = self.img_size\n",
        "        self.batch_size = batch_size\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
        "        return int(np.floor(len(self.ids) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data\"\"\"\n",
        "        indexes = self.indexes[index *\n",
        "                               self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        ids = [self.ids[k] for k in indexes]\n",
        "\n",
        "#         for id_ in [1820, 5915]:\n",
        "#             if id_ in ids:\n",
        "#                 ids.remove(id_)\n",
        "        X, y = self.__data_generation(ids)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\"\"\"\n",
        "        self.indexes = np.arange(len(self.ids))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, ids):\n",
        "        \"\"\"Generates data containing batch_size samples\"\"\"\n",
        "        for i, id_ in enumerate(ids):\n",
        "            img = cv2.imread(self.imgs[id_], cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                ids.remove(id_)\n",
        "                print(\"\\n==> Error id: \", id_)\n",
        "        size = len(ids)\n",
        "        \n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            X = np.ones([size, 1, self.img_w, self.img_h])\n",
        "        else:\n",
        "            X = np.ones([size, self.img_w, self.img_h, 1])\n",
        "        Y = np.ones([size, self.max_text_len])\n",
        "#         input_length = np.ones((size, 1), dtype=np.float32) * \\\n",
        "#             (self.img_w // self.downsample_factor - 2)\n",
        "        input_length = np.ones((size, 1), dtype=np.float32) * 254\n",
        "        label_length = np.zeros((size, 1), dtype=np.float32)\n",
        "\n",
        "        # Generate data\n",
        "        for i, id_ in enumerate(ids):\n",
        "            \n",
        "            img = cv2.imread(self.imgs[id_], cv2.IMREAD_GRAYSCALE)  # (h, w)\n",
        "            if img is None:\n",
        "                continue\n",
        "#             img = 255 - img  # bg: black, text: white\n",
        "            # bg: white, text: black\n",
        "            ratio = img.shape[0] / self.img_h\n",
        "            new_w = int(img.shape[1] / ratio) + 1\n",
        "            resized_image = cv2.resize(img, (new_w, self.img_h))  # (h, w)\n",
        "            img = cv2.copyMakeBorder(\n",
        "                resized_image, 0, 0, 0, self.img_w - resized_image.shape[1],\n",
        "                cv2.BORDER_CONSTANT, value=0\n",
        "            )  # (h, w)\n",
        "            img = img / 255  # (h, w)\n",
        "\n",
        "            if K.image_data_format() == 'channels_first':\n",
        "                img = np.expand_dims(img, 0)  # (1, h, w)\n",
        "                img = np.expand_dims((0, 2, 1))  # (1, w, h)\n",
        "            else:\n",
        "                img = np.expand_dims(img, -1)  # (h, w, 1)\n",
        "                img = img.transpose((1, 0, 2))  # (w, h, 1)\n",
        "\n",
        "            X[i] = img\n",
        "            text2label = text_to_labels(self.chars, self.gt_texts[id_])\n",
        "            Y[i] = text2label + \\\n",
        "                [self.blank_label for _ in range(\n",
        "                    self.max_text_len - len(text2label))]\n",
        "            label_length[i] = len(self.gt_texts[id_])\n",
        "\n",
        "        inputs = {\n",
        "            'the_input': X,\n",
        "            'the_labels': Y,\n",
        "            'input_length': input_length,\n",
        "            'label_length': label_length,\n",
        "        }\n",
        "        outputs = {'ctc': np.zeros([size])}\n",
        "\n",
        "        return (inputs, outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "di0kjTt0xKPF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(pretrained=False):\n",
        "\n",
        "    with open('drive/My Drive/Japanese_Recognition/datasets/transcription.pk', 'rb') as f:  # noqa\n",
        "        data = pickle.load(f)\n",
        "    no_samples = len(data)\n",
        "    no_train_set = int(no_samples * 0.95)\n",
        "    no_val_set = no_samples - no_train_set\n",
        "    logger.info(\"No train set: %d\", no_train_set)\n",
        "    logger.info(\"No val set: %d\", no_val_set)\n",
        "\n",
        "    train_set = TextSequenceGenerator(\n",
        "        data[:no_train_set],\n",
        "        img_size=img_size, max_text_len=256,\n",
        "        downsample_factor=4,\n",
        "        shuffle=True\n",
        "    )\n",
        "#     import pdb; pdb.set_trace()\n",
        "    test_set = TextSequenceGenerator(\n",
        "        data[no_train_set:],\n",
        "        img_size=img_size, max_text_len=256,\n",
        "        downsample_factor=4,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    model, y_func = CRNN_model()\n",
        "    model.load_weights('drive/My Drive/Japanese_Recognition/models/best_model_CTC_jps_25epochs.h5')\n",
        "    \n",
        "    sgd = SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
        "\n",
        "    ckp = ModelCheckpoint(\n",
        "        \"drive/My Drive/Japanese_Recognition/models/model_cp_CTC_jps.hdf5\".format(no_epochs), monitor='val_loss',\n",
        "        verbose=1, save_best_only=True, save_weights_only=True\n",
        "    )\n",
        "    earlystop = EarlyStopping(\n",
        "        monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'\n",
        "    )\n",
        "\n",
        "#     model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "#     model,\n",
        "#     strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "#         tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "    \n",
        "    model.fit_generator(generator=train_set,\n",
        "                        steps_per_epoch=no_train_set // 16,\n",
        "                        epochs=10,\n",
        "                        validation_data=test_set,\n",
        "                        validation_steps=no_val_set // 16,\n",
        "                        callbacks=[ckp, earlystop])\n",
        "\n",
        "    return model, y_func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zH4xYbt51ftm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.models import model_from_json\n",
        "\n",
        "# with open('drive/My Drive/Japanese_Recognition/models/config_jps_25epochs.json') as f:\n",
        "#     json_string = f.read()\n",
        "\n",
        "# model = model_from_json(json_string)\n",
        "# model.load_weights('drive/My Drive/Japanese_Recognition/models/best_model_CTC_jps_25epochs.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uNZZ66aHzf2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2193
        },
        "outputId": "415f1e9e-b53b-4cac-e7e9-4d4fbf3ae9e6"
      },
      "cell_type": "code",
      "source": [
        "model, y_func = train()\n",
        "\n",
        "model_json = model.to_json()\n",
        "# with open('drive/My Drive/Japanese_Recognition/models/config_jps_{}epochs.json'.format(no_epochs), 'w') as f:\n",
        "with open('drive/My Drive/Japanese_Recognition/models/config_jps.json', 'w') as f:\n",
        "    f.write(model_json)\n",
        "\n",
        "# model.save_weights('drive/My Drive/Japanese_Recognition/models/best_model_CTC_jps_{}epochs.h5'.format(no_epochs))\n",
        "model.save_weights('drive/My Drive/Japanese_Recognition/models/best_model_CTC_jps.h5')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-10-02 05:51:07,774 - __main__ - INFO - No train set: 6931\n",
            "2018-10-02 05:51:07,774 - __main__ - INFO - No train set: 6931\n",
            "2018-10-02 05:51:07,777 - __main__ - INFO - No val set: 365\n",
            "2018-10-02 05:51:07,777 - __main__ - INFO - No val set: 365\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(256, 572)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "the_input (InputLayer)          (None, 1150, 32, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 1150, 32, 64) 640         the_input[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max3 (MaxPooling2D)             (None, 575, 16, 64)  0           conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4 (Conv2D)                  (None, 575, 16, 128) 73856       max3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max4 (MaxPooling2D)             (None, 287, 8, 128)  0           conv4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv5 (Conv2D)                  (None, 287, 8, 256)  295168      max4[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "max5 (MaxPooling2D)             (None, 143, 4, 256)  0           conv5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 256, 572)     0           max5[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 256, 256)     146688      reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru1 (GRU)                      (None, 256, 256)     393984      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru1_b (GRU)                    (None, 256, 256)     393984      dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 256, 256)     0           gru1[0][0]                       \n",
            "                                                                 gru1_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "gru2 (GRU)                      (None, 256, 256)     393984      add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru2_b (GRU)                    (None, 256, 256)     393984      add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 256, 512)     0           gru2[0][0]                       \n",
            "                                                                 gru2_b[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 256, 216)     110808      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Activation)            (None, 256, 216)     0           dense2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,203,096\n",
            "Trainable params: 2,203,096\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "171/433 [==========>...................] - ETA: 13:48 - loss: 11.4404\n",
            "==> Error id:  5915\n",
            "391/433 [==========================>...] - ETA: 2:07 - loss: 11.1471\n",
            "==> Error id:  1820\n",
            "433/433 [==============================] - 1329s 3s/step - loss: 11.1013 - val_loss: 104.6010\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 104.60101, saving model to drive/My Drive/Japanese_Recognition/models/model_cp_CTC_jps_5epochs.hdf5\n",
            "Epoch 2/10\n",
            "270/433 [=================>............] - ETA: 8:14 - loss: 7.8187\n",
            "==> Error id:  5915\n",
            "369/433 [========================>.....] - ETA: 3:15 - loss: 7.9542\n",
            "==> Error id:  1820\n",
            "433/433 [==============================] - 1338s 3s/step - loss: 8.0230 - val_loss: 107.9795\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 104.60101\n",
            "Epoch 3/10\n",
            "\n",
            "==> Error id:  5915\n",
            "401/433 [==========================>...] - ETA: 1:34 - loss: 6.4892\n",
            "==> Error id:  1820\n",
            "433/433 [==============================] - 1294s 3s/step - loss: 6.4873 - val_loss: 110.5057\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 104.60101\n",
            "Epoch 4/10\n",
            "217/433 [==============>...............] - ETA: 10:01 - loss: 5.1715\n",
            "==> Error id:  1820\n",
            "306/433 [====================>.........] - ETA: 5:58 - loss: 5.1879\n",
            "==> Error id:  5915\n",
            "433/433 [==============================] - 1254s 3s/step - loss: 5.4033 - val_loss: 114.4405\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 104.60101\n",
            "Epoch 5/10\n",
            "128/433 [=======>......................] - ETA: 14:21 - loss: 4.2642\n",
            "==> Error id:  1820\n",
            "220/433 [==============>...............] - ETA: 10:11 - loss: 4.3803\n",
            "==> Error id:  5915\n",
            "433/433 [==============================] - 1283s 3s/step - loss: 4.5668 - val_loss: 116.1344\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 104.60101\n",
            "Epoch 6/10\n",
            "328/433 [=====================>........] - ETA: 4:52 - loss: 3.8675\n",
            "==> Error id:  5915\n",
            "396/433 [==========================>...] - ETA: 1:44 - loss: 3.8946\n",
            "==> Error id:  1820\n",
            "433/433 [==============================] - 1243s 3s/step - loss: 3.9127 - val_loss: 118.5728\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 104.60101\n",
            "Epoch 7/10\n",
            " 71/433 [===>..........................] - ETA: 17:39 - loss: 3.0929\n",
            "==> Error id:  1820\n",
            "242/433 [===============>..............] - ETA: 9:08 - loss: 3.1934\n",
            "==> Error id:  5915\n",
            "433/433 [==============================] - 1281s 3s/step - loss: 3.3894 - val_loss: 121.3854\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 104.60101\n",
            "Epoch 8/10\n",
            "143/433 [========>.....................] - ETA: 14:06 - loss: 2.6598\n",
            "==> Error id:  5915\n",
            "415/433 [===========================>..] - ETA: 51s - loss: 2.9476\n",
            "==> Error id:  1820\n",
            "433/433 [==============================] - 1247s 3s/step - loss: 2.9348 - val_loss: 123.6656\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 104.60101\n",
            "Epoch 9/10\n",
            " 78/433 [====>.........................] - ETA: 17:25 - loss: 2.3289\n",
            "==> Error id:  5915\n",
            "218/433 [==============>...............] - ETA: 10:32 - loss: 2.5800\n",
            "==> Error id:  1820\n",
            "433/433 [==============================] - 1292s 3s/step - loss: 2.6031 - val_loss: 125.9023\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 104.60101\n",
            "Epoch 10/10\n",
            "160/433 [==========>...................] - ETA: 13:17 - loss: 2.0951\n",
            "==> Error id:  5915\n",
            "165/433 [==========>...................] - ETA: 13:03 - loss: 2.0955\n",
            "==> Error id:  1820\n",
            "433/433 [==============================] - 1265s 3s/step - loss: 2.3249 - val_loss: 127.3151\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 104.60101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gGf3GQX5nPl2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "with open('drive/My Drive/Japanese_Recognition/models/config_jps_{}epochs.json'.format(no_epochs)) as f:\n",
        "    json_string = f.read()\n",
        "\n",
        "model = model_from_json(json_string)\n",
        "model.load_weights('drive/My Drive/Japanese_Recognition/models/best_model_CTC_jps_{}epochs.h5'.format(no_epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuWh-Ddlgwru",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_data = model.get_layer('the_input').output\n",
        "y_pred = model.get_layer('softmax').output\n",
        "model_p = Model(inputs=input_data, outputs=y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "af4rkQWihL8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08ca62db-4c5f-4bb7-b461-47f50ca3b443"
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('drive/My Drive/Japanese_Recognition/datasets/transcription.pk', 'rb') as f:  # noqa\n",
        "    data = pickle.load(f)\n",
        "no_samples = len(data)\n",
        "no_train_set = int(no_samples * 0.95)\n",
        "no_val_set = no_samples - no_train_set\n",
        "test_set = TextSequenceGenerator(\n",
        "    data[no_train_set:],\n",
        "    img_size=img_size, max_text_len=256,\n",
        "    downsample_factor=4,\n",
        "    shuffle=False\n",
        ")\n",
        "train_set = TextSequenceGenerator(\n",
        "    data[:no_train_set],\n",
        "    img_size=img_size, max_text_len=256,\n",
        "    downsample_factor=4,\n",
        "    shuffle=True\n",
        ")\n",
        "texts = []\n",
        "for sample in data:\n",
        "  texts.append(list(sample.values())[0])\n",
        "print(max(map(len, texts)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l5-4ScvQiHXU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import scipy.misc\n",
        "# scipy.misc.imsave('outfile.jpg', image_array)\n",
        "def predict(data_iter, index_batch, index_img):\n",
        "  samples = data_iter[index_batch]\n",
        "  img = samples[0]['the_input'][index_img]\n",
        "  # plt.imshow(np.squeeze(img).T)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  print(img.shape)\n",
        "  \n",
        "  net_out_value = model_p.predict(img)\n",
        "  print(net_out_value.shape)\n",
        "  pred_texts = top_pred_texts = decode_predict_ctc(net_out_value, chars_)\n",
        "  print(pred_texts[0].strip())\n",
        "  gt_texts = data_iter[index_batch][0]['the_labels'][index_img]\n",
        "  gt_texts = labels_to_text(chars_, gt_texts.astype(int))\n",
        "  print(gt_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KMeRUNTbNMZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "96f78810-b87d-4247-a32c-4c556b841a95"
      },
      "cell_type": "code",
      "source": [
        "for i in range(16):\n",
        "    predict(train_set, 1, i)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            ". Nơi đây cũng chỉ rừng và rừng, không một bóng nhà. Xe tải và ôtô đi về liên tục,\n",
            "Nơi đây cũng chỉ rừng và rừng, không một bóng nhà. Xe tải và ôtô đi về liên tục,\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "Qua báo chí, bản thân tôi đã được biết về việc tố cáo những sai phạm của\n",
            "Qua báo chí, bản thân tôi đã được biết về việc tố cáo những sai phạm của\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "đứng trước cửa nhà giam.\n",
            "đứng trước cửa nhà giam.\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "biết rằng cộng đồng NVƠN tuy vào khảng 2,7 triệu người nhưng tiềm lực\n",
            "biết rằng cộng đồng NVƠNN tuy vào khoảng 2,7 triệu người nhưng tiềm lực\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "được. Từ nhỏ cậu đã nuôi ước mơ trở thành cầu thủ bóng đá. Sau bao nỗ lực khổ\n",
            "được. Từ nhỏ cậu đã nuôi ước mơ trở thành cầu thủ bóng đá. Sau bao nỗ lực khổ\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "quan điều tra giải thích : ngoài nguyên nhân do thiếu. điều tra viên, còn\n",
            "quan điều tra giải thích : ngoài nguyên nhân do thiếu... điều tra viên, còn\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "chính nhờ khu nghĩa địa Từ Thiện mà qua mấy mùa nước lũ năm 20,\n",
            "chính nhờ khu nghĩa địa Từ Thiện mà qua mấy mùa nước lũ năm 2000,\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "đứa con cùng mình vác đi săn. Hầu như ngày nào ba bố con anh K.\n",
            "đứa con cùng mình vác đi săn. Hầu như ngày nào ba bố con anh K.\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            ".Trường hợp nào làm thay là phạm luật, chỉ có điều hiện nay các \" ông con \" không\n",
            "Trường hợp nào làm thay là phạm luật, chỉ có điều hiện nay các \" ông con \" không\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "tử rất mạnh được bà con Việt kiều quan tâm, trong đó có\n",
            "tử rất mạnh được bà con Việt kiều quan tâm, trong đó có\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "được gặp mặt PV.\n",
            "được gặp mặt PV.\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "Tiệc tráng chảo. Rượu mạnh pha cao hổ làm những tròng mắt đỏ rực vằn lên dưới ánh lửa.\n",
            "Tiệc tráng chảo. Rượu mạnh pha cao hổ làm những tròng mắt đỏ rực vằn lên dưới ánh lửa.\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "đã thường xuyên liên lạc với Trung tâm Tư vấn phòng chống AIDS của Đà\n",
            "đã thường xuyên liên lạc với Trung tâm Tư vấn phòng chống AIDS của Đà\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "NV2, NV3. Quan trọng là họ đã nỗ lực hết sức để khẳng định mình. Đó là ý nghĩa vẹn nguyên\n",
            "NV2, NV3. Quan trọng là họ đã nỗ lực hết sức để khẳng định mình. Đó là ý nghĩa vẹn nguyên\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            ", tưới vào cuối vụ đông xuân.\n",
            "tưới vào cuối vụ đông xuân.\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "nướng không bán nguyên con mà thường bán theo đĩa với giá bình quân\n",
            "nướng không bán nguyên con mà thường bán theo đĩa với giá bình quân\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PYT-qMB78p_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1105
        },
        "outputId": "3150912f-ed09-4a4a-aec6-2d8e93f01254"
      },
      "cell_type": "code",
      "source": [
        "for i in range(16):\n",
        "    predict(test_set, 1, i)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "Đên ạnh việc nghệ sế VNM& được tục hiều kiện vồi nưa biền chẩn\n",
            "Bên cạnh việc các nghệ sĩ NVƠNN được tạo điều kiện về nước biểu diễn\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "qhường quyễn, nhông\" tôi cũng trỉnh tới việc rối các ngiận vở hại sé\n",
            "thường xuyên, chúng tôi cũng tính tới cả việc mời các nghệ sĩ hoặc các\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "viên đơng rên gó vớn Kan thuan ga cá cộc Ti quốc sế dến mà cơ\n",
            "vận động viên gốc Việt tham gia các cuộc thi quốc tế dưới màu cờ\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "cải n, có Phểli ngàoy ti sêu muau tối, Mhím gòi gháp cốn sàng\n",
            "của VN, có thể là ngay tại Sea Games tới. Nhóm giải pháp cuối cùng\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "chúu trụng sử cá \" vẫn đề nhân trọ rì xùny dhọn cùng trn. Bà con sốc\n",
            "chú trọng tới các vấn đề nhân đạo và xây dựng lòng tin. Bà con sẽ\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "được tị điều liện tãn tà để về Phấn quêc, hề cangng tí trâng\n",
            "được tạo điều kiện tối đa để về thăm quê, thờ cúng tổ tiên.\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "gaái tmắn hai cn ó nhâu th củny công dung dà chền ở nớc sởđì dao\n",
            "Ngoài ra, nếu bà con có nhu cầu thờ cúng, xây chùa chiền ở nước sở tại,\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "xấi chủnh quền tổ tọi chếp nạn, trong nước xẽ cơ bện tột cạn thế. Nhôi\n",
            "nếu được chính quyền sở tại chấp nhận, trong nước sẽ có hỗ trợ cụ thể. Thưa\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "côg nôờn xốất lế đưc NV DN bán khêo án là tải cuất phý nhào của i\n",
            "ông, một vấn đề được nhiều NVƠNN băn khoăn là tư cách pháp nhân của bà\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "on bại nớc n tại để là con cơ kếu ơ túc nơ l lă mónh\n",
            "con tại nước sở tại để bà con có thể cư trú và làm ăn một\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "cỉh chính dúyt: xến đở nặy số trước vuan làân nm thượ ông \". Công hao\n",
            "cách chính đáng. Vấn đề này sẽ được quan tâm như thế nào thưa ông? - Vâng, theo\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "tính thền cải bộ Qnh Tu, 1ộ Ngại giao kẽ phải thu mui on cốn\n",
            "tinh thần của Bộ Chính trị, Bộ Ngoại giao sẽ phải tham mưu và kiến\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "phụ cụ thể đề đàn phạn và dị kốn vớc cầ nước nhuống hậy dịnh\n",
            "nghị cụ thể để đàm phán và ký kết với các nước những hiệp định\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "về 1 khấp cách phyếp gý cúnh công xâm V, ới dự như có kâng kợng lho\n",
            "về tư cách pháp lý của công dân VN, ví dụ như các hiệp định lãnh\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "é không tạnh lệ nưộ A phý.\n",
            "sự, hiệp định hỗ trợ tư pháp\n",
            "(1, 1150, 32, 1)\n",
            "(1, 256, 216)\n",
            "Ngài NK re minh rống ở nác ngài bừ nhiều kiàn cảnh khúc nhau, d\n",
            "Người VN ra sinh sống ở nước ngoài từ nhiều hoàn cảnh khác nhau, do\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pbLLt1bNBTyH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OVERFITTING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GB54wR7rPhFp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}